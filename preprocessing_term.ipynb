{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유형별 단어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_function(dirname):\n",
    "    filelist = os.listdir(dirname)\n",
    "    type_log_dict = defaultdict(lambda: 0)\n",
    "    pos_log_dict = defaultdict(lambda: [])\n",
    "    for file in filelist:\n",
    "        print(\"Now processing {}\".format(file))\n",
    "        log_type = file.split(\"_\")\n",
    "        log_type = log_type[2].split(\".\")[0]\n",
    "        f = pd.read_csv(dirname+\"\\\\\"+file, encoding='utf-8')\n",
    "        for i in f['corpus']:\n",
    "            result = twitter.pos(i)\n",
    "            for word, pos in result:\n",
    "                type_log_dict[log_type, word, pos] += 1\n",
    "    return type_log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing 4_0_expedition.csv\n",
      "Now processing 4_0_faction.csv\n",
      "Now processing 4_0_find-party.csv\n",
      "Now processing 4_0_party.csv\n",
      "Now processing 4_0_raid.csv\n",
      "Now processing 4_0_say.csv\n",
      "Now processing 4_0_trade.csv\n",
      "Now processing 4_0_whisper.csv\n",
      "Now processing 4_0_zone.csv\n",
      "Now processing 4_10_expedition.csv\n",
      "Now processing 4_10_faction.csv\n",
      "Now processing 4_10_find-party.csv\n",
      "Now processing 4_10_party.csv\n",
      "Now processing 4_10_raid.csv\n",
      "Now processing 4_10_say.csv\n",
      "Now processing 4_10_trade.csv\n",
      "Now processing 4_10_whisper.csv\n",
      "Now processing 4_10_zone.csv\n",
      "Now processing 4_1_expedition.csv\n",
      "Now processing 4_1_faction.csv\n",
      "Now processing 4_1_find-party.csv\n",
      "Now processing 4_1_party.csv\n",
      "Now processing 4_1_raid.csv\n",
      "Now processing 4_1_say.csv\n",
      "Now processing 4_1_trade.csv\n",
      "Now processing 4_1_whisper.csv\n",
      "Now processing 4_1_zone.csv\n",
      "Now processing 4_2_expedition.csv\n",
      "Now processing 4_2_faction.csv\n",
      "Now processing 4_2_find-party.csv\n",
      "Now processing 4_2_party.csv\n",
      "Now processing 4_2_raid.csv\n",
      "Now processing 4_2_say.csv\n",
      "Now processing 4_2_trade.csv\n",
      "Now processing 4_2_whisper.csv\n",
      "Now processing 4_2_zone.csv\n",
      "Now processing 4_3_expedition.csv\n",
      "Now processing 4_3_faction.csv\n",
      "Now processing 4_3_find-party.csv\n",
      "Now processing 4_3_party.csv\n",
      "Now processing 4_3_raid.csv\n",
      "Now processing 4_3_say.csv\n",
      "Now processing 4_3_trade.csv\n",
      "Now processing 4_3_whisper.csv\n",
      "Now processing 4_3_zone.csv\n",
      "Now processing 4_4_expedition.csv\n",
      "Now processing 4_4_faction.csv\n",
      "Now processing 4_4_find-party.csv\n",
      "Now processing 4_4_party.csv\n",
      "Now processing 4_4_raid.csv\n",
      "Now processing 4_4_say.csv\n",
      "Now processing 4_4_trade.csv\n",
      "Now processing 4_4_whisper.csv\n",
      "Now processing 4_4_zone.csv\n",
      "Now processing 4_5_expedition.csv\n",
      "Now processing 4_5_faction.csv\n",
      "Now processing 4_5_find-party.csv\n",
      "Now processing 4_5_party.csv\n",
      "Now processing 4_5_raid.csv\n",
      "Now processing 4_5_say.csv\n",
      "Now processing 4_5_trade.csv\n",
      "Now processing 4_5_whisper.csv\n",
      "Now processing 4_5_zone.csv\n",
      "Now processing 4_6_expedition.csv\n",
      "Now processing 4_6_faction.csv\n",
      "Now processing 4_6_find-party.csv\n",
      "Now processing 4_6_party.csv\n",
      "Now processing 4_6_raid.csv\n",
      "Now processing 4_6_say.csv\n",
      "Now processing 4_6_trade.csv\n",
      "Now processing 4_6_whisper.csv\n",
      "Now processing 4_6_zone.csv\n",
      "Now processing 4_7_expedition.csv\n",
      "Now processing 4_7_faction.csv\n",
      "Now processing 4_7_find-party.csv\n",
      "Now processing 4_7_party.csv\n",
      "Now processing 4_7_raid.csv\n",
      "Now processing 4_7_say.csv\n",
      "Now processing 4_7_trade.csv\n",
      "Now processing 4_7_whisper.csv\n",
      "Now processing 4_7_zone.csv\n",
      "Now processing 4_8_expedition.csv\n",
      "Now processing 4_8_faction.csv\n",
      "Now processing 4_8_find-party.csv\n",
      "Now processing 4_8_party.csv\n",
      "Now processing 4_8_raid.csv\n",
      "Now processing 4_8_say.csv\n",
      "Now processing 4_8_trade.csv\n",
      "Now processing 4_8_whisper.csv\n",
      "Now processing 4_8_zone.csv\n",
      "Now processing 4_9_expedition.csv\n",
      "Now processing 4_9_faction.csv\n",
      "Now processing 4_9_find-party.csv\n",
      "Now processing 4_9_party.csv\n",
      "Now processing 4_9_raid.csv\n",
      "Now processing 4_9_say.csv\n",
      "Now processing 4_9_trade.csv\n",
      "Now processing 4_9_whisper.csv\n",
      "Now processing 4_9_zone.csv\n",
      "Now processing 5_1_expedition.csv\n",
      "Now processing 5_1_faction.csv\n",
      "Now processing 5_1_family.csv\n",
      "Now processing 5_1_find-party.csv\n",
      "Now processing 5_1_party.csv\n",
      "Now processing 5_1_raid.csv\n",
      "Now processing 5_1_say.csv\n",
      "Now processing 5_1_trade.csv\n",
      "Now processing 5_1_whisper.csv\n",
      "Now processing 5_1_zone.csv\n",
      "Now processing 5_2_expedition.csv\n",
      "Now processing 5_2_faction.csv\n",
      "Now processing 5_2_family.csv\n",
      "Now processing 5_2_find-party.csv\n",
      "Now processing 5_2_party.csv\n",
      "Now processing 5_2_raid.csv\n",
      "Now processing 5_2_say.csv\n",
      "Now processing 5_2_trade.csv\n",
      "Now processing 5_2_whisper.csv\n",
      "Now processing 5_2_zone.csv\n",
      "Now processing 5_3_expedition.csv\n",
      "Now processing 5_3_faction.csv\n",
      "Now processing 5_3_family.csv\n",
      "Now processing 5_3_find-party.csv\n",
      "Now processing 5_3_party.csv\n",
      "Now processing 5_3_raid.csv\n",
      "Now processing 5_3_say.csv\n",
      "Now processing 5_3_trade.csv\n",
      "Now processing 5_3_whisper.csv\n",
      "Now processing 5_3_zone.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "a = type_function(\"total\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    with open('./type_result/{}.csv'.format(i[0]), 'a', encoding='utf-8', newline='\\n') as writefile:\n",
    "        writer = csv.writer(writefile)\n",
    "        writer.writerow([i[1], i[2], a[i]])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주별 단어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_function(dirname):\n",
    "    filelist = os.listdir(dirname)\n",
    "    now = '4_0'\n",
    "    week_log_dict = defaultdict(lambda: 0)\n",
    "    \n",
    "    for file in filelist:\n",
    "        print(\"Now processing {}\".format(file), now)\n",
    "        week_type = file.split(\"_\")\n",
    "        temp = week_type[0]+\"_\"+week_type[1]\n",
    "        \n",
    "        f = pd.read_csv(dirname+\"\\\\\"+file, encoding='utf-8')\n",
    "        for i in f['corpus']:\n",
    "            result = twitter.pos(i)\n",
    "            for word, pos in result:\n",
    "                week_log_dict[word, pos] += 1\n",
    "                \n",
    "        temp1 = now\n",
    "        if not temp == temp1:\n",
    "            with open('./week_result/{}.csv'.format(temp1), 'a', encoding='utf-8', newline='\\n') as writefile:\n",
    "                writer = csv.writer(writefile)\n",
    "                for i in week_log_dict:\n",
    "                    writer.writerow([i[0], i[1], week_log_dict[i]])\n",
    "            week_log_dict = defaultdict(lambda: 0)\n",
    "            now = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "week_function(\"total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBT별 단어 분석\n",
    "##### 병렬처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CBT_function(dirname):\n",
    "    filelist = os.listdir(dirname)\n",
    "    type_log_dict = defaultdict(lambda: 0)\n",
    "    for file in filelist:\n",
    "        print(\"Now processing {}\".format(file))\n",
    "        CBT_type = file.split(\"_\")[0]\n",
    "        f = pd.read_csv(dirname+\"\\\\\"+file, encoding='utf-8')\n",
    "        for i in f['corpus']:\n",
    "            result = twitter.pos(i)\n",
    "            for word, pos in result:\n",
    "                type_log_dict[week_type, word, pos] += 1\n",
    "    return type_log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbt = CBT_function(\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cbt:\n",
    "    with open('./cbt_result/{}.csv'.format(i[0]), 'a', encoding='utf-8', newline='\\n') as writefile:\n",
    "        writer = csv.writer(writefile)\n",
    "        writer.writerow([i[1], i[2], cbt[i]])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBT dict 총길이 749309"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
